#### 如何为主机和设备分配内存空间？

对应的由标准C函数和CUDA C函数来实现。

执行GPU内存分配的是 `cudaMalloc`函数，其函数原型为：

```c
cudaError_t cudaMalloc(void** devPtr, size_t size)
//devPtr 为指向分配内存空间首地址的指针
//size 为申请的内存空间大小
```

#### 如何在主机和设备之间传输数据？

`cudaMemcpy` 函数负责主机和设备之间的数据传输，由哪里拷贝到哪里？则由函数中的`kind`参数进行指定。先看下函数原型：

```c
cudaError_t cudaMemcpy(void* dst, const void* src, size_t count,
                      cudaMemcpyKind kind)
//参数kind指定了数据拷贝的方向
```

`kind`的参数有下面的几种，从名字就可以看出拷贝的去向。

+ cudaMemcpyHostToHost
+ cudaMemcpyHostToDevice
+ cudaMemcpyDeviceToHost
+ cudaMemcpyDeviceToDevice

需要注意的是，cudaMemcpy 函数会阻塞进程，返回值用于表示内存分配是否成功，有两个标志 `cudaSuccess` 和 `cudaErrorMemoryAllocation`。如果想要读取这个错误信息，需要转换一下，用下面的方式：

```c
char* cudaGetErrorString(cudaError_t error)
```

对于把数据从主机拷贝到设备端的情况，完成数据的拷贝后，内核函数就会被主机端调用。一旦内核函数被调用，控制权就会立即被传回到主机，继续执行主机端的代码。因此内核与主机是异步的。

#### 线程管理

当主机端调用内核函数后，设备端会起多个线程来执行该内核函数，那么线程在编程模型中是如何抽象的呢？一个内核函数启动产生的所有线程统称为一个网格，按我的理解，应该是一张卡算是一个网格。同一个网格中的所有线程共享相同的全局内存空间。

一个网络有多个线程块构成，每个线程块在网格中的位置由`blockIdx`给出，每个线程块内的线程可以由 `threadIdx` 来索引。CUDA在运行时会为每个线程指定 `blockIdx` 和`threadIdx` ，这样就确定了该线程的坐标。

变量 `blockIdx` , `threadIdx` ,  `blockDim` 和 `threadDim` 是CUDA预定义的，直接拿来用即可。类型为`dim3`，是一个三维的数组。代表的意思如下：

blockIdx : 当前执行内核函数的线程所属的block在grid内的位置索引

threadIdx: 当前执行内核函数的线程在所属block内的位置索引

下面举个例子说明一下：

```c
int main(int argc, char **argv){
    int nElem = 6; //使用6个线程
  
    //下面定义block和grid的维度
    dim3 b(3,1,1); //一个block容纳3个线程，也可以直接写作 dim3 b(3)，其它维默认为1
    dim3 g((nElem+b.x-1) / b.x); //计算grid的维度

    printf("grid.x %d grid.y %d grid.z %d\n", g.x, g.y, g.z); //输出三个不同维度的大小
    printf("block.x %d block.y %d block.z %d \n", b.x, b.y, b.z);

    checkIndex<<<g, b>>> (); //调用内核函数的时候，需要传入grid和block的维度参数
    cudaDeviceReset();
    return(0);
}
```

看下内核函数是怎么调用内置变量来获取位置和维度信息的。

```c
__global__ void checkIndex(void){
    printf("threadIdx: (%d, %d, %d)"
           "blockIdx: (%d, %d, %d)"
           "blockDim: (%d, %d, %d)"
           "gridDim: (%d, %d, %d)\n", 
           
           //获取当前线程在所属block内的位置信息
           threadIdx.x, 
           threadIdx.y, 
           threadIdx.z,
           
           //获取当前线程所属的block在grid内的位置信息
           blockIdx.x, 
           blockIdx.y, 
           blockIdx.z, 
           
           //获取当前线程所属的block的维度（容量）信息
           blockDim.x, 
           blockDim.y, 
           blockDim.z,
           
           //获取当前线程所属的block所在的grid的维度（容量）信息
           gridDim.x, 
           gridDim.y, 
           gridDim.z);
}
```

如果要重新改变一个block的大小，直接对要改变的维度赋值即可以了，比如：`b.x = 128;`

我们知道内核函数的执行是异步的，也就是说当内核函数被调用后，就继续执行主机代码了，当然也可以强制等待内核函数执行结束，像下面这样：

```c
checkIndex<<<g, b>>> ();
cudaError_t flag = cudaDeviceSynchronize(); //强制等待核函数checkIndex执行完毕
                                            //并保存返回值信息
const char *msg = cudaGetErrorString(flag); //转换返回值信息
printf("%s\n", msg);                        //打印返回值信息
```

函数原型 `cudaError_t cudaDeviceSynchronize(void)`

